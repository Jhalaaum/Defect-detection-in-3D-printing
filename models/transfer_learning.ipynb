{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import shutil\n",
    "from pathlib import Path, PurePath\n",
    "import json\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Import the new library\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from torchvision import transforms as T\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES = './train/images'\n",
    "MASKS = './train/masks'\n",
    "classes_csv = './train/_classes.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class porosity_Dataset(Dataset):\n",
    "    def __init__(self, image_path, mask_path, x, mean, std, transform=None, patch=False,\n",
    "                 image_ext=\".jpg\", mask_ext=\".png\"):\n",
    "        self.img_path = image_path\n",
    "        self.mask_path = mask_path\n",
    "        self.x = x\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.transform = transform\n",
    "        self.patch = patch\n",
    "        self.image_ext = image_ext\n",
    "        self.mask_ext = mask_ext\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_filename = self.x[idx] + self.image_ext\n",
    "        mask_filename = self.x[idx] + \"_mask\" + self.mask_ext\n",
    "        img_path = os.path.join(self.img_path, image_filename)\n",
    "        mask_path = os.path.join(self.mask_path, mask_filename)\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if img.shape[:2] != mask.shape[:2]:\n",
    "            mask = cv2.resize(mask, (img.shape[1], img.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=img, mask=mask)\n",
    "            img = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        # Normalization and tensor conversion\n",
    "        t = T.Compose([T.ToTensor(), T.Normalize(self.mean, self.std)])\n",
    "        img = t(img)\n",
    "        mask = torch.from_numpy(mask).long()\n",
    "\n",
    "        if self.patch:\n",
    "            img, mask = self.tiles(img, mask)\n",
    "            \n",
    "        return img, mask\n",
    "\n",
    "    def tiles(self, img, mask, size=256, threshold=0.01, min_classes=2):\n",
    "        img_patches = img.unfold(1, size, size).unfold(2, size, size)\n",
    "        img_patches = img_patches.contiguous().view(3, -1, size, size).permute(1, 0, 2, 3)\n",
    "\n",
    "        mask_patches = mask.unfold(0, size, size).unfold(1, size, size)\n",
    "        mask_patches = mask_patches.contiguous().view(-1, size, size)\n",
    "\n",
    "        keep_indices = []\n",
    "        for i, patch in enumerate(mask_patches):\n",
    "            unique_classes = torch.unique(patch)\n",
    "            fg = (patch != 0).sum().item()\n",
    "            ratio = fg / (size * size)\n",
    "            if len(unique_classes) >= min_classes or ratio > threshold or np.random.rand() < 0.1:\n",
    "                keep_indices.append(i)\n",
    "\n",
    "        if not keep_indices:\n",
    "            keep_indices.append(np.random.randint(0, len(img_patches)))\n",
    "\n",
    "        return img_patches[keep_indices], mask_patches[keep_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    images = [item[0] for item in batch]\n",
    "    masks = [item[1] for item in batch]\n",
    "    return images, masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None, gamma=2, ignore_index=-100):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.ce = nn.CrossEntropyLoss(weight=weight, ignore_index=ignore_index)\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logpt = -self.ce(input, target)\n",
    "        pt = torch.exp(logpt)\n",
    "        loss = ((1 - pt) ** self.gamma) * -logpt\n",
    "        return loss.mean()\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, n_classes, ignore_index=None):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def forward(self, input, target, smooth=1e-6):\n",
    "        input_soft = F.softmax(input, dim=1)\n",
    "        \n",
    "        if self.ignore_index is not None:\n",
    "            mask = target != self.ignore_index\n",
    "            target = target[mask]\n",
    "            input_soft = input_soft.permute(0, 2, 3, 1)[mask.unsqueeze(-1).expand_as(input_soft.permute(0, 2, 3, 1))]\n",
    "            input_soft = input_soft.reshape(-1, self.n_classes)\n",
    "\n",
    "\n",
    "        target_one_hot = F.one_hot(target, num_classes=self.n_classes).float()\n",
    "        \n",
    "        input_flat = input_soft.contiguous().view(-1)\n",
    "        target_flat = target_one_hot.contiguous().view(-1)\n",
    "        \n",
    "        intersection = (input_flat * target_flat).sum()\n",
    "        dice_score = (2. * intersection + smooth) / (input_flat.sum() + target_flat.sum() + smooth)\n",
    "        return 1 - dice_score\n",
    "\n",
    "class DiceFocalLoss(nn.Module):\n",
    "    def __init__(self, n_classes, weight=None, gamma=2, alpha=0.5, ignore_index=-100):\n",
    "        super(DiceFocalLoss, self).__init__()\n",
    "        self.focal_loss = FocalLoss(weight=weight, gamma=gamma, ignore_index=ignore_index)\n",
    "        self.dice_loss = DiceLoss(n_classes=n_classes, ignore_index=ignore_index)\n",
    "        self.alpha = alpha\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        focal = self.focal_loss(input, target)\n",
    "        dice = self.dice_loss(input, target)\n",
    "        return self.alpha * focal + (1 - self.alpha) * dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_accuracy(output, mask):\n",
    "    with torch.no_grad():\n",
    "        output = torch.argmax(F.softmax(output, dim=1), dim=1)\n",
    "        correct = torch.eq(output, mask).int()\n",
    "        accuracy = float(correct.sum()) / float(correct.numel())\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mIoU(pred_mask, mask, smooth=1e-10, n_classes=12):\n",
    "    with torch.no_grad():\n",
    "        pred_mask = F.softmax(pred_mask, dim=1)\n",
    "        pred_mask = torch.argmax(pred_mask, dim=1)\n",
    "        pred_mask = pred_mask.contiguous().view(-1)\n",
    "        mask = mask.contiguous().view(-1)\n",
    "        \n",
    "        iou_per_class = []\n",
    "        for c in range(n_classes):\n",
    "            true_class = pred_mask == c\n",
    "            true_label = mask == c\n",
    "            \n",
    "            if true_label.long().sum().item() == 0:\n",
    "                iou_per_class.append(np.nan)\n",
    "            else:\n",
    "                intersect = torch.logical_and(true_class, true_label).sum().float().item()\n",
    "                union = torch.logical_or(true_class, true_label).sum().float().item()\n",
    "                iou = (intersect + smooth) / (union + smooth)\n",
    "                iou_per_class.append(iou)\n",
    "        return np.nanmean(iou_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_per_class_iou(preds, labels, num_classes=12):\n",
    "    ious = []\n",
    "    preds = preds.view(-1)\n",
    "    labels = labels.view(-1)\n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = preds == cls\n",
    "        label_inds = labels == cls\n",
    "        intersection = (pred_inds & label_inds).sum().item()\n",
    "        union = (pred_inds | label_inds).sum().item()\n",
    "        if union == 0:\n",
    "            ious.append(float('nan'))\n",
    "        else:\n",
    "            ious.append(intersection / union)\n",
    "    return ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, train_loader, val_loader, criterion, optimizer, scheduler, patch=False, num_classes=12):\n",
    "    train_losses, val_losses = [], []\n",
    "    train_iou, val_iou = [], []\n",
    "    train_acc, val_acc = [], []\n",
    "    lrs = []\n",
    "    min_loss = np.inf\n",
    "    no_improve = 0\n",
    "\n",
    "    model.to(device)\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        model.train()\n",
    "        running_loss, running_iou, running_acc, total_batches = 0, 0, 0, 0\n",
    "\n",
    "        for image_tiles, mask_tiles in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\"):\n",
    "            images = torch.cat(image_tiles, dim=0).to(device)\n",
    "            masks = torch.cat(mask_tiles, dim=0).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_iou += mIoU(outputs, masks)\n",
    "            running_acc += pixel_accuracy(outputs, masks)\n",
    "            total_batches += 1\n",
    "            lrs.append(get_lr(optimizer))\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_iou_score, val_accuracy, val_batches = 0, 0, 0, 0\n",
    "        all_class_ious = []\n",
    "        with torch.no_grad():\n",
    "            for image_tiles, mask_tiles in tqdm(val_loader, desc=f\"Epoch {epoch+1} Validation\"):\n",
    "                images = torch.cat(image_tiles, dim=0).to(device)\n",
    "                masks = torch.cat(mask_tiles, dim=0).to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                val_loss += criterion(outputs, masks).item()\n",
    "                val_iou_score += mIoU(outputs, masks)\n",
    "                val_accuracy += pixel_accuracy(outputs, masks)\n",
    "\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                for pred, true_mask in zip(preds, masks):\n",
    "                    all_class_ious.append(compute_per_class_iou(pred, true_mask, num_classes))\n",
    "                val_batches += 1\n",
    "        \n",
    "        avg_train_loss = running_loss / total_batches\n",
    "        avg_val_loss = val_loss / val_batches\n",
    "        avg_train_iou = running_iou / total_batches\n",
    "        avg_val_iou = val_iou_score / val_batches\n",
    "        avg_train_acc = running_acc / total_batches\n",
    "        avg_val_acc = val_accuracy / val_batches\n",
    "\n",
    "        train_losses.append(avg_train_loss); val_losses.append(avg_val_loss)\n",
    "        train_iou.append(avg_train_iou); val_iou.append(avg_val_iou)\n",
    "        train_acc.append(avg_train_acc); val_acc.append(avg_val_acc)\n",
    "        \n",
    "        mean_class_ious = np.nanmean(np.array(all_class_ious), axis=0)\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}] - \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, \"\n",
    "              f\"Train mIoU: {avg_train_iou:.4f}, Val mIoU: {avg_val_iou:.4f}, \"\n",
    "              f\"Train Acc: {avg_train_acc:.4f}, Val Acc: {avg_val_acc:.4f}, \"\n",
    "              f\"LR: {lrs[-1]:.6f}, \"\n",
    "              f\"Time: {(time.time() - epoch_start)/60:.2f} mins\")\n",
    "\n",
    "        print(\"\\n📊 Per-class IoU (Validation):\")\n",
    "        for i, iou in enumerate(mean_class_ious):\n",
    "            print(f\"  Class {i}: IoU = {iou:.4f}\")\n",
    "\n",
    "        if avg_val_loss < min_loss:\n",
    "            print(f\"Validation loss decreased ({min_loss:.4f} -> {avg_val_loss:.4f}). Saving model.\")\n",
    "            min_loss = avg_val_loss\n",
    "            no_improve = 0\n",
    "            torch.save(model.state_dict(), 'model_transfer_learning.pt')\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            print(f\"No improvement in validation loss for {no_improve} epochs.\")\n",
    "            if no_improve >= 10:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    total_time = (time.time() - start_time) / 60\n",
    "    print(f\"\\nTraining completed in {total_time:.2f} minutes.\")\n",
    "    history = {'train_loss': train_losses, 'val_loss': val_losses, 'train_miou': train_iou, 'val_miou': val_iou, 'train_acc': train_acc, 'val_acc': val_acc, 'lrs': lrs}\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train = A.Compose([A.VerticalFlip(), A.HorizontalFlip(), A.GridDistortion(p=0.2),\n",
    "                     A.GaussNoise(), A.RandomBrightnessContrast((0, 0.5), (0, 0.5))])\n",
    "t_val = A.Compose([A.HorizontalFlip(), A.GridDistortion(p=0.2)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = sorted([os.path.splitext(f)[0] for f in os.listdir(IMAGES)])\n",
    "x_temp, x_test = train_test_split(x_all, test_size=0.10, random_state=42)\n",
    "x_train, x_val = train_test_split(x_temp, test_size=0.10, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = porosity_Dataset(IMAGES, MASKS, x_train, mean, std, t_train, patch=True)\n",
    "val_dataset = porosity_Dataset(IMAGES, MASKS, x_val, mean, std, t_val, patch=True)\n",
    "test_dataset = porosity_Dataset(IMAGES, MASKS, x_test, mean, std, t_val, patch=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class distribution: [111525788    308867    313560  20404741     44311    113133         0\n",
      "         0         0         0         0         0]\n",
      "Val class distribution: [12824773     3203     5703  2093855     4623    10051        0        0\n",
      "        0        0        0        0]\n"
     ]
    }
   ],
   "source": [
    "def get_class_distribution(dataset, num_classes=12):\n",
    "    class_counts = np.zeros(num_classes, dtype=int)\n",
    "    for _, mask in DataLoader(dataset, batch_size=1):\n",
    "        for m in mask:\n",
    "            for cls in range(num_classes):\n",
    "                class_counts[cls] += torch.sum(m == cls).item()\n",
    "    return class_counts\n",
    "\n",
    "train_class_counts = get_class_distribution(train_dataset)\n",
    "val_class_counts = get_class_distribution(val_dataset)\n",
    "\n",
    "print(\"Train class distribution:\", train_class_counts)\n",
    "print(\"Val class distribution:\", val_class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): UnetDecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): UnetDecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): UnetDecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): UnetDecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): UnetDecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",        # A powerful and well-tested encoder\n",
    "    encoder_weights=\"imagenet\",     # Use weights pre-trained on ImageNet\n",
    "    in_channels=3,                  # Number of input channels (3 for RGB)\n",
    "    classes=12,                     # Number of output classes\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights_from_masks(\n",
    "    masks_dir, \n",
    "    num_classes=12, \n",
    "    background_class_id=0, \n",
    "    background_weight_multiplier=0.1\n",
    "):\n",
    "    class_counts = np.zeros(num_classes, dtype=np.int64)\n",
    "    total_pixels = 0\n",
    "\n",
    "    for mask_name in os.listdir(masks_dir):\n",
    "        if mask_name.endswith(\".png\"):\n",
    "            mask_path = os.path.join(masks_dir, mask_name)\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            if mask is not None:\n",
    "                total_pixels += mask.size\n",
    "                for cls in range(num_classes):\n",
    "                    class_counts[cls] += np.sum(mask == cls)\n",
    "    class_frequencies = class_counts / total_pixels\n",
    "    class_frequencies[class_frequencies == 0] = 1e-6\n",
    "    class_weights = 1.0 / class_frequencies\n",
    "    class_weights[background_class_id] *= background_weight_multiplier\n",
    "    class_weights = class_weights * (num_classes / np.sum(class_weights))\n",
    "    return torch.tensor(class_weights, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = get_class_weights_from_masks(MASKS, num_classes=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weights.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lr = 1e-3\n",
    "epoch = 30\n",
    "weight_decay = 1e-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = DiceFocalLoss(n_classes=12, weight=class_weights, gamma=2, alpha=0.5, ignore_index=0)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epoch, steps_per_epoch=len(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:   1%|▏         | 3/236 [00:27<34:39,  8.93s/it]"
     ]
    }
   ],
   "source": [
    "history = fit(epoch, model, train_loader, val_loader, criterion, optimizer, scheduler, patch=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history['val_loss'], label='val', marker='o')\n",
    "    plt.plot(history['train_loss'], label='train', marker='o')\n",
    "    plt.title('Loss per epoch'); plt.ylabel('loss');\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(), plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_score(history):\n",
    "    plt.plot(history['train_miou'], label='train_mIoU', marker='*')\n",
    "    plt.plot(history['val_miou'], label='val_mIoU',  marker='*')\n",
    "    plt.title('Score per epoch'); plt.ylabel('mean IoU')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(), plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_acc(history):\n",
    "    plt.plot(history['train_acc'], label='train_accuracy', marker='*')\n",
    "    plt.plot(history['val_acc'], label='val_accuracy',  marker='*')\n",
    "    plt.title('Accuracy per epoch'); plt.ylabel('Accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(), plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss(history)\n",
    "plot_score(history)\n",
    "plot_acc(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
